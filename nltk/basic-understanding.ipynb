{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Natural Language Toolkit (nltk)** is a powerful Python library used for working with human language data (text). It provides easy-to-use interfaces to over 50 corpora and lexical resources, along with a suite of text-processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to NLP and NLTK\n",
    "Natural Language Processing (NLP) is a branch of artificial intelligence that deals with interaction between computers and humans through natural language. It’s crucial for tasks like:\n",
    "\n",
    "1. Text Classification\n",
    "2. Sentiment Analysis\n",
    "3. Named Entity Recognition (NER)\n",
    "4. Machine Translation\n",
    "\n",
    "The `nltk` library simplifies NLP tasks by providing a large toolkit with pre-built functionalities to manipulate and analyze textual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation of NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\tfs\\study\\natural-language-processing\\.venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\tfs\\study\\natural-language-processing\\.venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\tfs\\study\\natural-language-processing\\.venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\tfs\\study\\natural-language-processing\\.venv\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\tfs\\study\\natural-language-processing\\.venv\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\tfs\\study\\natural-language-processing\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\tfs\\study\\natural-language-processing\\.venv\\lib\\site-packages (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once installed, you can download the necessary datasets and models using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Text Processing with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization\n",
    "Breaking down text into smaller parts like sentences or words is the first step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Sentence Tokenization:** Tokenizes a paragraph into individual sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello!', 'Welcome to the world of NLTK.', 'This is a simple example.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "text = \"Hello! Welcome to the world of NLTK. This is a simple example.\"\n",
    "sentences = sent_tokenize(text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Word Tokenization:** Tokenizes sentences into individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', '!', 'Welcome', 'to', 'the', 'world', 'of', 'NLTK', '.', 'This', 'is', 'a', 'simple', 'example', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text = \"Hello! Welcome to the world of NLTK. This is a simple example.\"\n",
    "words = word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords Removal\n",
    "Many words in a language (like \"the,\" \"is,\" \"in\") don’t carry much meaning in terms of analysis. These are called stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', '!', 'Welcome', 'world', 'NLTK', '.', 'This', 'simple', 'example', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "text = \"Hello! Welcome to the world of NLTK. This is a simple example.\"\n",
    "words = word_tokenize(text)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [w for w in words if not w in stop_words]\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming and Lemmatization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming** is like a quick cut to simplify words, whereas **lemmatization** is like getting back to the dictionary form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming**: Reducing words to their root form by chopping off prefixes, suffixes, converting to all small case etc. (e.g., \"Running\" → \"run\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', '!', 'welcom', 'world', 'nltk', '.', 'thi', 'simpl', 'exampl', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "stemmed = [ps.stem(w) for w in filtered_words]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatization**: Similar to stemming but returns valid words. It uses vocabulary and morphological analysis (e.g., \"running\" → \"run\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', '!', 'Welcome', 'world', 'NLTK', '.', 'This', 'simple', 'example', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmed = [lemmatizer.lemmatize(w) for w in filtered_words]\n",
    "print(lemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What is Morphological Analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Morphological analysis** in the context of **lemmatization** refers to the process of understanding the structure and formation of words to reduce them to their base or dictionary form, known as the **lemma**. It involves analyzing the various grammatical forms a word can take (like tense, gender, or number) and understanding how these forms are constructed through inflectional changes (prefixes, suffixes, etc.).\n",
    "\n",
    "**Key Concepts:**\n",
    "1. **Lemmatization**: The process of reducing a word to its base or dictionary form (lemma).\n",
    "2. **Morphology**: The study of the structure of words and how they change to express grammatical features like tense, number, etc.\n",
    "\n",
    "**How Morphological Analysis Works in Lemmatization:**\n",
    "When lemmatization is applied, it looks at both the word's **morphology** (form and structure) and **context** to find its base form. This is different from **stemming**, which simply cuts off word endings without regard to grammatical rules or context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1: Verb Conjugation**\n",
    "Take the word \"running\":\n",
    "\n",
    "1. **Morphological Analysis**: The word \"running\" is a present participle of the verb \"run\". The \"-ing\" suffix indicates a continuous action.\n",
    "2. **Lemmatization**: The base form or lemma of \"running\" is \"run\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Example\n",
    "print(lemmatizer.lemmatize('running', pos='v'))  # Verb context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2: Nouns with Plural Forms**\n",
    "For the word \"geese\":\n",
    "\n",
    "1. **Morphological Analysis**: The word \"geese\" is the plural form of \"goose\". In English, it uses an irregular plural form.\n",
    "2. **Lemmatization**: The lemma or base form is \"goose\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goose\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize('geese', pos='n'))  # Noun context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 3: Adjectives with Comparative and Superlative Forms**\n",
    "For the word \"better\":\n",
    "\n",
    "1. **Morphological Analysis**: \"Better\" is the comparative form of \"good\". Morphologically, it represents a higher degree of goodness.\n",
    "2. **Lemmatization**: The lemma is \"good\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize('better', pos='a'))  # Adjective context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Morphological Rules Considered in Lemmatization:**\n",
    "1. **Verb tenses**: Runs → run, Running → run, Ran → run\n",
    "2. **Plural nouns**: Geese → goose, Dogs → dog\n",
    "3. **Comparative/superlative adjectives**: Better → good, Best → good\n",
    "4. **Inflectional endings**: Laughing → laugh, Studies → study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importance in Natural Language Processing (NLP):**\n",
    "Morphological analysis through lemmatization ensures that words with different grammatical forms (tenses, plurals, etc.) are understood as the same root concept. This is particularly useful for tasks like text classification, sentiment analysis, and search engines, where word variants should be treated uniformly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging (Parts of Speech Tagging)\n",
    "This step involves labeling words with their respective parts of speech (nouns, verbs, adjectives, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hello', 'NN'), ('!', '.'), ('Welcome', 'UH'), ('to', 'TO'), ('the', 'DT'), ('world', 'NN'), ('of', 'IN'), ('NLTK', 'NNP'), ('.', '.'), ('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('simple', 'JJ'), ('example', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "tagged = pos_tag(words)\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER)\n",
    "Identifying proper names in text (people, places, organizations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk\n",
    "entities = ne_chunk(tagged)\n",
    "entities.draw()  # Visual representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification with NLTK\n",
    "NLTK provides functionality for building basic text classifiers. A simple text classification pipeline includes:\n",
    "\n",
    "1. Feature extraction\n",
    "2. Training classifiers (Naive Bayes, Decision Trees, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction\n",
    "Convert textual data into a format that machine learning models can understand. Bag of Words (BoW) is a common approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 2), ('Hello', 1), ('!', 1), ('Welcome', 1), ('to', 1)]\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "fdist = FreqDist(words)\n",
    "print(fdist.most_common(5))  # Most common words as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Classification Example (Naive Bayes)\n",
    "We’ll classify whether a piece of text is about sports or politics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7675\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "\n",
    "def extract_features(word_list):\n",
    "    return {word: True for word in word_list}\n",
    "\n",
    "movie_reviews_data = [(extract_features(list(movie_reviews.words(fileid))), category)\n",
    "                      for category in movie_reviews.categories()\n",
    "                      for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(movie_reviews_data)\n",
    "train_data = movie_reviews_data[:1600]\n",
    "test_data = movie_reviews_data[1600:]\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_data)\n",
    "print(f\"Accuracy: {accuracy(classifier, test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNet - Lexical Database\n",
    "WordNet is a lexical (anything related to words or vocabulary) database for the English language that groups words into sets of synonyms called synsets and provides meanings and relationships between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a motor vehicle with four wheels; usually propelled by an internal combustion engine\n",
      "a wheeled vehicle adapted to the rails of railroad\n",
      "the compartment that is suspended from an airship and that carries personnel and the cargo and the power plant\n",
      "where passengers ride up and down\n",
      "a conveyance for passengers or freight on a cable railway\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "synonyms = wordnet.synsets(\"car\")\n",
    "for synonym in synonyms:\n",
    "    print(synonym.definition())  # Print the definition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying NLTK for Machine Learning\n",
    "NLTK’s text processing tools are foundational for building machine learning models. Here’s an example of how you might approach an NLP problem using NLTK with machine learning models:\n",
    "\n",
    "1. **Preprocess the text**: Tokenization, stopwords removal, stemming/lemmatization.\n",
    "2. **Feature Extraction**: Extract features using BoW, TF-IDF, or word embeddings.\n",
    "3. **Model Building**: Use classifiers like Naive Bayes, SVM, or neural networks (RNN, LSTM) on the processed data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
